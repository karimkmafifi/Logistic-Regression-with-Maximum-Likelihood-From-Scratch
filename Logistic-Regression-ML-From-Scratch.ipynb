{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Logistic Regression with Maximum Likelihood From Scratch</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is a very popular algorithm used for classification. The algorithm is mainly designed for binary classification problems but can be easily expanded to multi-class ones.<br> The algorithm is used to predict the probability that sample x<sub>i</sub> belongs to class 1: P(y<sub>i</sub>=1|x<sub>i</sub>;&Theta;). After calculating the probability that sample x<sub>i</sub> belongs to class 1, we need to assign a class to x<sub>i</sub>; this is done using a decision boundary. While there are multiple types of decision boundaries that can be used, a general rule of thumb is: if prob>=0.5: class=1 else: class=0.<br><br>\n",
    "<b>How do we calculate the probability that sample x<sub>i</sub> belongs to class 1?</b><br>\n",
    "While in linear regression we use &Theta;<sup>T</sup>X to predict our continous variable (-inf to +inf), we need to transform our predictions to the probability that sample x<sub>i</sub> belongs to class 1; this is done using the sigmoid function (a.k.a logistic function). The equation for the sigmoid function is: h(x)= 1/1+e<sup>-&Theta;<sup>T</sup>x</sup><br>\n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/8/88/Logistic-curve.svg' alt=\"Sigmoid Function (a.k.a Logistic Function)\"/>\n",
    "<br><br>\n",
    "<b>Now that we know how to predict the probability that x<sub>i</sub> belongs to class 1, how do we solve for &Theta;? In other words, how do we find the optimal values for our parameters &Theta;?</b><br>\n",
    "We need to maximize the <b>likelihood function</b>. The likelihood of our model parameterized by &Theta given our observations.<br>\n",
    "So after selecting our parameters &Theta;, we can assess the fit of our model (sigmoid function) parametrized by &Theta by calculating the likelihood.<br>\n",
    "The likelihood is calculated by multiplying the predicted probability (p) for observations that belong to class 1 by 1 - the predicted probability (1-p) for observations that belong to class 0. In other words, the likelihood function rewards our model for predicting a high probability for observations that belong to class 1 and for predicting a low probability for observations that belong to class 0.<br>\n",
    "Imagine the following, we have 2 fitted models that we need to compare. We will calculate the likelihood for the 2 fitted models and the one that maximizes the likelihood function, is the better fit.<br>\n",
    "\n",
    "<table style=\"margin-left: 50px; text-align: center;\" >\n",
    "<tr>\n",
    "    <th>Model 1</th>\n",
    "</tr>\n",
    "<tr>\n",
    "    <th style=\"text-align: center; border: 1px solid black;\">P</th>\n",
    "    <th style=\"text-align: center; border: 1px solid black;\">1-P</th>\n",
    "    <th style=\"text-align: center; border: 1px solid black;\">Real Class</th>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td style=\"text-align: center; border: 1px solid black;\">0.6</td>\n",
    "    <td style=\"text-align: center; border: 1px solid black;\">-</td>\n",
    "    <td style=\"text-align: center; border: 1px solid black;\">1</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td style=\"text-align: center; border: 1px solid black;\">0.7</td>\n",
    "    <td style=\"text-align: center; border: 1px solid black;\">-</td>\n",
    "    <td style=\"text-align: center; border: 1px solid black;\">1</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td style=\"text-align: center; border: 1px solid black;\">-</td>\n",
    "    <td style=\"text-align: center; border: 1px solid black;\">0.5</td>\n",
    "    <td style=\"text-align: center; border: 1px solid black;\">0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td style=\"text-align: center; border: 1px solid black;\">-</td>\n",
    "    <td style=\"text-align: center; border: 1px solid black;\">0.6</td>\n",
    "    <td style=\"text-align: center; border: 1px solid black;\">0</td>\n",
    "</tr>\n",
    "</table> \n",
    "\n",
    "<table style=\"margin-left: 50px; text-align: center;\" >\n",
    "<tr>\n",
    "    <th>Model 2</th>\n",
    "</tr>\n",
    "<tr>\n",
    "    <th style=\"text-align: center; border: 1px solid black;\">P</th>\n",
    "    <th style=\"text-align: center; border: 1px solid black;\">1-P</th>\n",
    "    <th style=\"text-align: center; border: 1px solid black;\">Real Class</th>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td style=\"text-align: center; border: 1px solid black;\">0.8</td>\n",
    "    <td style=\"text-align: center; border: 1px solid black;\">-</td>\n",
    "    <td style=\"text-align: center; border: 1px solid black;\">1</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td style=\"text-align: center; border: 1px solid black;\">0.75</td>\n",
    "    <td style=\"text-align: center; border: 1px solid black;\">-</td>\n",
    "    <td style=\"text-align: center; border: 1px solid black;\">1</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td style=\"text-align: center; border: 1px solid black;\">-</td>\n",
    "    <td style=\"text-align: center; border: 1px solid black;\">0.89</td>\n",
    "    <td style=\"text-align: center; border: 1px solid black;\">0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td style=\"text-align: center; border: 1px solid black;\">-</td>\n",
    "    <td style=\"text-align: center; border: 1px solid black;\">0.8</td>\n",
    "    <td style=\"text-align: center; border: 1px solid black;\">0</td>\n",
    "</tr>\n",
    "</table>\n",
    "<br clear=\"all\"/>\n",
    "\n",
    "Likelihood for Model 1: p * p * (1-P) * (1-p): 0.6 * 0.7 * 0.5 * 0.6: 0.126<br>\n",
    "Likelihood for Model 2: p * p * (1-P) * (1-p): 0.8 * 0.75 * 0.89 * 0.8: 0.4272<br>\n",
    "\n",
    "The likelihood for Model 2 is higher than Model 1 therefore, Model 2 is a better fit to our data.<br><br>\n",
    "\n",
    "Now that we know how to assess the fit of our model, we need to solve for the parameters &Theta;. In other words, we need to maximize the likelihood function. And what do we use in order to maximize or minimize a certain function? <b>Differentiation</b><br>\n",
    "\n",
    "Taking the derivative of the likelihood function as the product of the probabilities is hard and not computationally efficient therefore, we will use the <b>log</b> of the likelihood function. An explaination of why taking the derivative of the log likelihood function is possible, more efficient and will result in the same value of theta: <a href='https://stats.stackexchange.com/q/174481'>https://stats.stackexchange.com/q/174481</a> & <a href='https://www.youtube.com/watch?v=ddqny3aZNPY'>https://www.youtube.com/watch?v=ddqny3aZNPY</a> <br>\n",
    "\n",
    "For example, to calculate the log likelihood for Model 1, log(likelihood): log(p * p * (1-P) * (1-p)) and since log(ab) = log(a) + log(b), now, to calculate the log likelihood for Model 1, log(likelihood): log(p) + log(p) + log(1-P) + log(1-p)<br>\n",
    "Since the log of any value between 0 and 1 is negative, we will add a negative sign to the log(likelihood) function: -log(likelihood)<br>\n",
    "After adding a negative sign infront of the log(likelihood) function, this function (-log(likelihood)) is now called the <b>cross-entropy</b>. So, minimizing the cross-entropy is the same as maximizing the likelihood.<br><br>\n",
    "\n",
    "Finally, the cross-entropy function for a binary classifier that we need to minimize is:<br>\n",
    "<img src=\"https://miro.medium.com/max/1096/1*rdBw0E-My8Gu3f_BOB6GMA.png\" alt=\"Cross-entropy function for binary classification\" height=\"300px\" width=\"500px\"/>\n",
    "\n",
    "N = Number of samples<br>\n",
    "y<sub>i</sub> = Real value (0 or 1)<br>\n",
    "p(y<sub>i</sub>) = predicted probability<br>\n",
    "\n",
    "If an observation has a real value or class of 1, the log(p(y<sub>i</sub>)) is calculated and if the real value is 0, the log(1-p(y<sub>i</sub>)) is calculated.\n",
    "<br><br>\n",
    "\n",
    "So now that we want to minimize our cross-entropy model, we will use gradient descent for such task. In order to make use of the gradient descent optimization algorithm, we need to find the derivative of the cross-entropy with respect to weights. The final equation is:<br>\n",
    "<img src=\"https://predictiveprogrammer.com/wp-content/uploads/2018/11/dj_by_dw.jpg\" alt=\"Derivative of cross-entropy\" height=\"200px\" width=\"300px\"/>\n",
    "\n",
    "m = Number of samples<br>\n",
    "y = Real value (0 or 1)<br>\n",
    "y<sub>hat</sub> = predicted probability<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will implement a simple logistic regression algorithm with only one feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=100, centers=2, n_features=1, cluster_std=1.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dim=np.zeros(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa4ec038780>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=X, y=temp_dim, hue=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n_iters = 1000\n",
    "learning_rate = 0.01\n",
    "weight = 0\n",
    "bias = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sigmoid(weighted_x):\n",
    "    return 1.0/(1.0 + np.exp(-weighted_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_th_trans_x(x_values):\n",
    "    return x_values * weight + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probs(x_values):\n",
    "    weighted_x = get_linear_th_trans_x(x_values)\n",
    "    probs = get_sigmoid(weighted_x)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cross_entropy(probs, y_values):\n",
    "    cross_entropy = -np.mean(y_values * np.log(probs + 1e-10) + (1 - y_values) * np.log((1 - probs) + 1e-10))\n",
    "    return cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(probs, y_values):\n",
    "    predicted_classes=probs>=0.5\n",
    "    return np.mean(predicted_classes==y_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6931471803599453\n",
      "0.6666682029447365\n",
      "0.6445324964522545\n",
      "0.6259779191795467\n",
      "0.6103638628920456\n",
      "0.5971615594274576\n",
      "0.5859393945053475\n",
      "0.5763471889809775\n",
      "0.5681015250313903\n",
      "0.5609729894337804\n",
      "0.5547755306129029\n",
      "0.5493577954095981\n",
      "0.5445961799319671\n",
      "0.5403893011664506\n",
      "0.5366536164539137\n",
      "0.533319956416212\n",
      "0.5303307785581189\n",
      "0.527637986988263\n",
      "0.525201196192931\n",
      "0.5229863432851678\n",
      "0.5209645742259978\n",
      "0.5191113460397221\n",
      "0.5174056998945139\n",
      "0.5158296698662644\n",
      "0.5143677998897738\n",
      "0.5130067473410952\n",
      "0.5117349562911008\n",
      "0.510542387035063\n",
      "0.5094202912757104\n",
      "0.5083610245010255\n",
      "0.507357888792845\n",
      "0.5064050006348504\n",
      "0.5054971793403873\n",
      "0.5046298525541916\n",
      "0.503798975945451\n",
      "0.5030009647396261\n",
      "0.5022326351615862\n",
      "0.5014911542049676\n",
      "0.5007739964194367\n",
      "0.5000789066321376\n",
      "0.499403867702538\n",
      "0.49874707255943207\n",
      "0.4981068998915362\n",
      "0.4974818929640977\n",
      "0.49687074111734475\n",
      "0.4962722635717185\n",
      "0.49568539522228006\n",
      "0.4951091741525821\n",
      "0.49454273063836496\n",
      "0.4939852774450296\n",
      "0.4934361012511044\n",
      "0.4928945550537577\n",
      "0.49236005143256784\n",
      "0.49183205656484263\n",
      "0.4913100849003179\n",
      "0.49079369441542947\n",
      "0.4902824823779284\n",
      "0.4897760815616571\n",
      "0.489274156859062\n",
      "0.4887764022456964\n",
      "0.4882825380567155\n",
      "0.4877923085403305\n",
      "0.48730547965748167\n",
      "0.4868218371007179\n",
      "0.48634118450849495\n",
      "0.48586334185392577\n",
      "0.48538814398946\n",
      "0.48491543933111536\n",
      "0.48444508866775193\n",
      "0.48397696408251994\n",
      "0.4835109479750547\n",
      "0.48304693217424577\n",
      "0.48258481713253565\n",
      "0.48212451119366706\n",
      "0.4816659299266769\n",
      "0.4812089955196912\n",
      "0.480753636227757\n",
      "0.4802997858695475\n",
      "0.4798473833683037\n",
      "0.4793963723328579\n",
      "0.4789467006749989\n",
      "0.4784983202598137\n",
      "0.4780511865859808\n",
      "0.4776052584932815\n",
      "0.4771604978948682\n",
      "0.4767168695320638\n",
      "0.476274340749682\n",
      "0.47583288129005047\n",
      "0.4753924631040888\n",
      "0.47495306017794975\n",
      "0.47451464837387275\n",
      "0.47407720528401764\n",
      "0.47364071009616887\n",
      "0.4732051434702914\n",
      "0.4727704874250228\n",
      "0.4723367252332572\n",
      "0.4719038413260616\n",
      "0.4714718212042263\n",
      "0.4710406513568163\n",
      "0.4706103191861448\n",
      "0.47018081293863945\n",
      "0.469752121641119\n",
      "0.46932423504204157\n",
      "0.46889714355731743\n",
      "0.46847083822031993\n",
      "0.46804531063575744\n",
      "0.46762055293709465\n",
      "0.4671965577472421\n",
      "0.4667733181422536\n",
      "0.4663508276177926\n",
      "0.4659290800581509\n",
      "0.46550806970761743\n",
      "0.4650877911440139\n",
      "0.46466823925422834\n",
      "0.4642494092115905\n",
      "0.4638312964549473\n",
      "0.46341389666930566\n",
      "0.4629972057679236\n",
      "0.46258121987573697\n",
      "0.4621659353140196\n",
      "0.46175134858618455\n",
      "0.46133745636463636\n",
      "0.4609242554785979\n",
      "0.46051174290283486\n",
      "0.4600999157472126\n",
      "0.45968877124702157\n",
      "0.4592783067540126\n",
      "0.45886851972809045\n",
      "0.45845940772961596\n",
      "0.4580509684122694\n",
      "0.457643199516437\n",
      "0.4572360988630778\n",
      "0.4568296643480377\n",
      "0.4564238939367768\n",
      "0.45601878565947906\n",
      "0.45561433760651715\n",
      "0.45521054792424487\n",
      "0.4548074148110947\n",
      "0.4544049365139566\n",
      "0.4540031113248183\n",
      "0.453601937577648\n",
      "0.4532014136455004\n",
      "0.4528015379378331\n",
      "0.4524023088980133\n",
      "0.45200372500100505\n",
      "0.45160578475122193\n",
      "0.45120848668053365\n",
      "0.4508118293464155\n",
      "0.45041581133022957\n",
      "0.4500204312356299\n",
      "0.4496256876870808\n",
      "0.4492315793284809\n",
      "0.44883810482188585\n",
      "0.4484452628463219\n",
      "0.4480530520966841\n",
      "0.44766147128271194\n",
      "0.4472705191280403\n",
      "0.44688019436931475\n",
      "0.44649049575537314\n",
      "0.4461014220464822\n",
      "0.44571297201363097\n",
      "0.44532514443787274\n",
      "0.4449379381097144\n",
      "0.44455135182854927\n",
      "0.44416538440212977\n",
      "0.44378003464607785\n",
      "0.44339530138343025\n",
      "0.4430111834442155\n",
      "0.44262767966506117\n",
      "0.44224478888883006\n",
      "0.44186250996427995\n",
      "0.4414808417457497\n",
      "0.44109978309286635\n",
      "0.44071933287027354\n",
      "0.44033948994737926\n",
      "0.4399602531981208\n",
      "0.4395816215007476\n",
      "0.43920359373761836\n",
      "0.43882616879501357\n",
      "0.4384493455629606\n",
      "0.4380731229350717\n",
      "0.43769749980839323\n",
      "0.4373224750832664\n",
      "0.4369480476631967\n",
      "0.4365742164547338\n",
      "0.4362009803673593\n",
      "0.4358283383133831\n",
      "0.43545628920784657\n",
      "0.43508483196843334\n",
      "0.43471396551538594\n",
      "0.4343436887714286\n",
      "0.43397400066169584\n",
      "0.4336049001136665\n",
      "0.43323638605710046\n",
      "0.43286845742398405\n",
      "0.43250111314847467\n",
      "0.43213435216685303\n",
      "0.43176817341747736\n",
      "0.4314025758407407\n",
      "0.4310375583790325\n",
      "0.4306731199767017\n",
      "0.4303092595800234\n",
      "0.429945976137168\n",
      "0.4295832685981722\n",
      "0.4292211359149121\n",
      "0.428859577041079\n",
      "0.4284985909321565\n",
      "0.428138176545399\n",
      "0.4277783328398126\n",
      "0.4274190587761372\n",
      "0.42706035331682946\n",
      "0.4267022154260475\n",
      "0.42634464406963735\n",
      "0.42598763821511876\n",
      "0.42563119683167405\n",
      "0.42527531889013676\n",
      "0.42492000336298136\n",
      "0.42456524922431366\n",
      "0.42421105544986243\n",
      "0.42385742101697144\n",
      "0.42350434490459204\n",
      "0.4231518260932763\n",
      "0.42279986356517096\n",
      "0.4224484563040122\n",
      "0.4220976032951197\n",
      "0.4217473035253926\n",
      "0.4213975559833051\n",
      "0.4210483596589018\n",
      "0.42069971354379554\n",
      "0.42035161663116244\n",
      "0.42000406791574035\n",
      "0.41965706639382516\n",
      "0.41931061106326944\n",
      "0.418964700923479\n",
      "0.4186193349754116\n",
      "0.41827451222157563\n",
      "0.4179302316660274\n",
      "0.41758649231437034\n",
      "0.4172432931737541\n",
      "0.41690063325287224\n",
      "0.4165585115619626\n",
      "0.4162169271128052\n",
      "0.41587587891872246\n",
      "0.4155353659945778\n",
      "0.4151953873567752\n",
      "0.41485594202325904\n",
      "0.4145170290135132\n",
      "0.41417864734856097\n",
      "0.41384079605096435\n",
      "0.41350347414482436\n",
      "0.41316668065578044\n",
      "0.41283041461101044\n",
      "0.41249467503923026\n",
      "0.41215946097069384\n",
      "0.4118247714371934\n",
      "0.41149060547205896\n",
      "0.41115696211015845\n",
      "0.4108238403878978\n",
      "0.410491239343221\n",
      "0.4101591580156098\n",
      "0.40982759544608405\n",
      "0.40949655067720164\n",
      "0.40916602275305847\n",
      "0.4088360107192888\n",
      "0.40850651362306484\n",
      "0.4081775305130971\n",
      "0.4078490604396343\n",
      "0.40752110245446377\n",
      "0.407193655610911\n",
      "0.40686671896383964\n",
      "0.4065402915696521\n",
      "0.40621437248628933\n",
      "0.40588896077323033\n",
      "0.4055640554914929\n",
      "0.4052396557036332\n",
      "0.40491576047374556\n",
      "0.40459236886746314\n",
      "0.40426947995195717\n",
      "0.40394709279593705\n",
      "0.4036252064696507\n",
      "0.40330382004488385\n",
      "0.40298293259496043\n",
      "0.4026625431947424\n",
      "0.40234265092062904\n",
      "0.4020232548505576\n",
      "0.4017043540640026\n",
      "0.40138594764197616\n",
      "0.40106803466702684\n",
      "0.40075061422324065\n",
      "0.4004336853962398\n",
      "0.40011724727318326\n",
      "0.39980129894276556\n",
      "0.3994858394952177\n",
      "0.3991708680223057\n",
      "0.3988563836173311\n",
      "0.3985423853751301\n",
      "0.3982288723920735\n",
      "0.3979158437660663\n",
      "0.3976032985965472\n",
      "0.39729123598448823\n",
      "0.3969796550323946\n",
      "0.3966685548443037\n",
      "0.39635793452578516\n",
      "0.39604779318394023\n",
      "0.3957381299274012\n",
      "0.3954289438663309\n",
      "0.39512023411242236\n",
      "0.39481199977889786\n",
      "0.3945042399805091\n",
      "0.3941969538335359\n",
      "0.393890140455786\n",
      "0.3935837989665941\n",
      "0.3932779284868219\n",
      "0.39297252813885686\n",
      "0.3926675970466116\n",
      "0.3923631343355235\n",
      "0.3920591391325541\n",
      "0.39175561056618785\n",
      "0.39145254776643185\n",
      "0.39114994986481516\n",
      "0.3908478159943876\n",
      "0.39054614528971954\n",
      "0.39024493688690065\n",
      "0.3899441899235396\n",
      "0.3896439035387626\n",
      "0.3893440768732132\n",
      "0.3890447090690512\n",
      "0.3887457992699517\n",
      "0.3884473466211043\n",
      "0.3881493502692123\n",
      "0.3878518093624919\n",
      "0.38755472305067085\n",
      "0.38725809048498805\n",
      "0.3869619108181922\n",
      "0.3866661832045412\n",
      "0.3863709067998009\n",
      "0.38607608076124433\n",
      "0.3857817042476504\n",
      "0.3854877764193033\n",
      "0.38519429643799125\n",
      "0.3849012634670056\n",
      "0.3846086766711393\n",
      "0.38431653521668674\n",
      "0.38402483827144174\n",
      "0.3837335850046972\n",
      "0.3834427745872436\n",
      "0.38315240619136776\n",
      "0.3828624789908524\n",
      "0.38257299216097423\n",
      "0.38228394487850303\n",
      "0.38199533632170113\n",
      "0.381707165670321\n",
      "0.38141943210560536\n",
      "0.38113213481028496\n",
      "0.38084527296857823\n",
      "0.38055884576618937\n",
      "0.3802728523903072\n",
      "0.3799872920296049\n",
      "0.37970216387423716\n",
      "0.37941746711584023\n",
      "0.37913320094752984\n",
      "0.3788493645639006\n",
      "0.37856595716102415\n",
      "0.37828297793644805\n",
      "0.3780004260891946\n",
      "0.3777183008197592\n",
      "0.3774366013301094\n",
      "0.37715532682368336\n",
      "0.3768744765053883\n",
      "0.37659404958159964\n",
      "0.376314045260159\n",
      "0.37603446275037333\n",
      "0.3757553012630133\n",
      "0.375476560010312\n",
      "0.37519823820596326\n",
      "0.37492033506512057\n",
      "0.37464284980439555\n",
      "0.3743657816418562\n",
      "0.374089129797026\n",
      "0.37381289349088204\n",
      "0.3735370719458535\n",
      "0.37326166438582065\n",
      "0.37298667003611297\n",
      "0.3727120881235074\n",
      "0.3724379178762279\n",
      "0.37216415852394247\n",
      "0.37189080929776286\n",
      "0.37161786943024244\n",
      "0.3713453381553747\n",
      "0.3710732147085919\n",
      "0.3708014983267633\n",
      "0.37053018824819406\n",
      "0.3702592837126228\n",
      "0.36998878396122087\n",
      "0.36971868823659054\n",
      "0.3694489957827631\n",
      "0.36917970584519744\n",
      "0.368910817670779\n",
      "0.36864233050781675\n",
      "0.36837424360604326\n",
      "0.3681065562166118\n",
      "0.36783926759209556\n",
      "0.36757237698648537\n",
      "0.36730588365518824\n",
      "0.367039786855026\n",
      "0.3667740858442333\n",
      "0.3665087798824561\n",
      "0.3662438682307497\n",
      "0.36597935015157784\n",
      "0.3657152249088099\n",
      "0.3654514917677202\n",
      "0.36518814999498556\n",
      "0.36492519885868413\n",
      "0.36466263762829343\n",
      "0.3644004655746886\n",
      "0.3641386819701407\n",
      "0.3638772860883151\n",
      "0.3636162772042697\n",
      "0.3633556545944529\n",
      "0.3630954175367024\n",
      "0.3628355653102429\n",
      "0.36257609719568457\n",
      "0.3623170124750215\n",
      "0.3620583104316296\n",
      "0.3617999903502648\n",
      "0.3615420515170616\n",
      "0.36128449321953104\n",
      "0.36102731474655886\n",
      "0.3607705153884039\n",
      "0.36051409443669613\n",
      "0.3602580511844351\n",
      "0.3600023849259875\n",
      "0.35974709495708634\n",
      "0.359492180574828\n",
      "0.3592376410776714\n",
      "0.3589834757654356\n",
      "0.35872968393929794\n",
      "0.3584762649017924\n",
      "0.3582232179568081\n",
      "0.3579705424095865\n",
      "0.35771823756672033\n",
      "0.35746630273615165\n",
      "0.3572147372271697\n",
      "0.3569635403504091\n",
      "0.3567127114178482\n",
      "0.3564622497428071\n",
      "0.3562121546399456\n",
      "0.35596242542526135\n",
      "0.3557130614160883\n",
      "0.3554640619310946\n",
      "0.35521542629028025\n",
      "0.35496715381497623\n",
      "0.3547192438278414\n",
      "0.35447169565286163\n",
      "0.3542245086153473\n",
      "0.35397768204193153\n",
      "0.35373121526056817\n",
      "0.35348510760053026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3532393583924075\n",
      "0.3529939669681049\n",
      "0.3527489326608405\n",
      "0.35250425480514364\n",
      "0.35225993273685263\n",
      "0.35201596579311367\n",
      "0.3517723533123777\n",
      "0.35152909463439963\n",
      "0.3512861891002356\n",
      "0.3510436360522413\n",
      "0.3508014348340702\n",
      "0.35055958479067123\n",
      "0.35031808526828706\n",
      "0.35007693561445213\n",
      "0.34983613517799056\n",
      "0.3495956833090144\n",
      "0.34935557935892136\n",
      "0.34911582268039315\n",
      "0.3488764126273934\n",
      "0.3486373485551653\n",
      "0.34839862982023045\n",
      "0.3481602557803861\n",
      "0.3479222257947037\n",
      "0.3476845392235264\n",
      "0.3474471954284676\n",
      "0.3472101937724086\n",
      "0.34697353361949673\n",
      "0.34673721433514354\n",
      "0.3465012352860223\n",
      "0.34626559584006644\n",
      "0.3460302953664677\n",
      "0.34579533323567346\n",
      "0.3455607088193856\n",
      "0.34532642149055764\n",
      "0.3450924706233933\n",
      "0.3448588555933445\n",
      "0.34462557577710895\n",
      "0.3443926305526285\n",
      "0.3441600192990869\n",
      "0.3439277413969082\n",
      "0.3436957962277541\n",
      "0.34346418317452243\n",
      "0.343232901621345\n",
      "0.34300195095358565\n",
      "0.342771330557838\n",
      "0.34254103982192347\n",
      "0.34231107813488965\n",
      "0.3420814448870079\n",
      "0.3418521394697714\n",
      "0.3416231612758931\n",
      "0.34139450969930385\n",
      "0.3411661841351502\n",
      "0.34093818397979253\n",
      "0.3407105086308029\n",
      "0.340483157486963\n",
      "0.3402561299482624\n",
      "0.3400294254158961\n",
      "0.33980304329226274\n",
      "0.3395769829809626\n",
      "0.33935124388679566\n",
      "0.3391258254157591\n",
      "0.3389007269750457\n",
      "0.33867594797304185\n",
      "0.3384514878193252\n",
      "0.33822734592466286\n",
      "0.33800352170100934\n",
      "0.3377800145615043\n",
      "0.33755682392047087\n",
      "0.3373339491934133\n",
      "0.33711138979701516\n",
      "0.33688914514913726\n",
      "0.33666721466881533\n",
      "0.33644559777625843\n",
      "0.33622429389284647\n",
      "0.3360033024411287\n",
      "0.3357826228448211\n",
      "0.33556225452880484\n",
      "0.33534219691912387\n",
      "0.3351224494429831\n",
      "0.3349030115287463\n",
      "0.334683882605934\n",
      "0.33446506210522164\n",
      "0.33424654945843735\n",
      "0.33402834409855997\n",
      "0.333810445459717\n",
      "0.33359285297718266\n",
      "0.3333755660873758\n",
      "0.3331585842278577\n",
      "0.33294190683733044\n",
      "0.3327255333556344\n",
      "0.3325094632237464\n",
      "0.33229369588377805\n",
      "0.33207823077897297\n",
      "0.33186306735370535\n",
      "0.3316482050534778\n",
      "0.3314336433249192\n",
      "0.3312193816157825\n",
      "0.3310054193749433\n",
      "0.3307917560523972\n",
      "0.330578391099258\n",
      "0.33036532396775586\n",
      "0.33015255411123473\n",
      "0.32994008098415106\n",
      "0.3297279040420712\n",
      "0.32951602274166963\n",
      "0.32930443654072683\n",
      "0.3290931448981274\n",
      "0.32888214727385784\n",
      "0.3286714431290047\n",
      "0.3284610319257525\n",
      "0.3282509131273815\n",
      "0.3280410861982663\n",
      "0.32783155060387287\n",
      "0.3276223058107576\n",
      "0.32741335128656424\n",
      "0.32720468650002277\n",
      "0.32699631092094694\n",
      "0.3267882240202323\n",
      "0.326580425269854\n",
      "0.32637291414286534\n",
      "0.32616569011339525\n",
      "0.3259587526566465\n",
      "0.3257521012488935\n",
      "0.32554573536748055\n",
      "0.3253396544908198\n",
      "0.325133858098389\n",
      "0.32492834567072976\n",
      "0.32472311668944537\n",
      "0.32451817063719907\n",
      "0.32431350699771155\n",
      "0.3241091252557595\n",
      "0.32390502489717343\n",
      "0.32370120540883546\n",
      "0.3234976662786776\n",
      "0.3232944069956796\n",
      "0.32309142704986693\n",
      "0.322888725932309\n",
      "0.3226863031351171\n",
      "0.32248415815144227\n",
      "0.3222822904754733\n",
      "0.322080699602435\n",
      "0.3218793850285862\n",
      "0.3216783462512172\n",
      "0.3214775827686487\n",
      "0.3212770940802291\n",
      "0.3210768796863329\n",
      "0.3208769390883585\n",
      "0.3206772717887265\n",
      "0.32047787729087746\n",
      "0.32027875509927\n",
      "0.3200799047193789\n",
      "0.3198813256576932\n",
      "0.31968301742171423\n",
      "0.31948497951995314\n",
      "0.31928721146192984\n",
      "0.3190897127581703\n",
      "0.318892482920205\n",
      "0.3186955214605667\n",
      "0.31849882789278877\n",
      "0.318302401731403\n",
      "0.318106242491938\n",
      "0.3179103496909164\n",
      "0.3177147228458542\n",
      "0.31751936147525767\n",
      "0.3173242650986221\n",
      "0.3171294332364295\n",
      "0.31693486541014704\n",
      "0.31674056114222454\n",
      "0.31654651995609295\n",
      "0.31635274137616254\n",
      "0.3161592249278206\n",
      "0.3159659701374299\n",
      "0.31577297653232594\n",
      "0.3155802436408165\n",
      "0.3153877709921782\n",
      "0.3151955581166554\n",
      "0.31500360454545834\n",
      "0.3148119098107607\n",
      "0.31462047344569816\n",
      "0.3144292949843663\n",
      "0.3142383739618186\n",
      "0.31404770991406483\n",
      "0.31385730237806886\n",
      "0.3136671508917468\n",
      "0.31347725499396517\n",
      "0.3132876142245392\n",
      "0.3130982281242304\n",
      "0.3129090962347453\n",
      "0.31272021809873296\n",
      "0.31253159325978364\n",
      "0.31234322126242653\n",
      "0.3121551016521279\n",
      "0.31196723397528947\n",
      "0.3117796177792462\n",
      "0.31159225261226464\n",
      "0.3114051380235411\n",
      "0.31121827356319937\n",
      "0.31103165878228956\n",
      "0.31084529323278537\n",
      "0.310659176467583\n",
      "0.31047330804049883\n",
      "0.3102876875062678\n",
      "0.31010231442054115\n",
      "0.30991718833988513\n",
      "0.3097323088217788\n",
      "0.3095476754246122\n",
      "0.3093632877076846\n",
      "0.30917914523120243\n",
      "0.30899524755627794\n",
      "0.30881159424492666\n",
      "0.30862818486006616\n",
      "0.30844501896551385\n",
      "0.3082620961259853\n",
      "0.3080794159070926\n",
      "0.3078969778753418\n",
      "0.3077147815981321\n",
      "0.30753282664375325\n",
      "0.3073511125813841\n",
      "0.30716963898109056\n",
      "0.306988405413824\n",
      "0.3068074114514193\n",
      "0.306626656666593\n",
      "0.3064461406329418\n",
      "0.3062658629249402\n",
      "0.30608582311793914\n",
      "0.30590602078816415\n",
      "0.30572645551271327\n",
      "0.3055471268695557\n",
      "0.3053680344375295\n",
      "0.30518917779634036\n",
      "0.305010556526559\n",
      "0.3048321702096205\n",
      "0.3046540184278214\n",
      "0.30447610076431875\n",
      "0.3042984168031278\n",
      "0.30412096612912043\n",
      "0.30394374832802357\n",
      "0.30376676298641697\n",
      "0.30359000969173183\n",
      "0.30341348803224893\n",
      "0.3032371975970967\n",
      "0.3030611379762497\n",
      "0.30288530876052666\n",
      "0.302709709541589\n",
      "0.30253433991193857\n",
      "0.3023591994649165\n",
      "0.30218428779470125\n",
      "0.30200960449630637\n",
      "0.3018351491655795\n",
      "0.3016609213992004\n",
      "0.30148692079467887\n",
      "0.30131314695035327\n",
      "0.30113959946538904\n",
      "0.3009662779397765\n",
      "0.30079318197432936\n",
      "0.30062031117068305\n",
      "0.30044766513129295\n",
      "0.3002752434594325\n",
      "0.3001030457591919\n",
      "0.29993107163547583\n",
      "0.2997593206940021\n",
      "0.2995877925413001\n",
      "0.2994164867847087\n",
      "0.2992454030323749\n",
      "0.2990745408932515\n",
      "0.29890389997709643\n",
      "0.2987334798944704\n",
      "0.2985632802567349\n",
      "0.29839330067605124\n",
      "0.29822354076537844\n",
      "0.2980540001384718\n",
      "0.2978846784098808\n",
      "0.29771557519494785\n",
      "0.2975466901098064\n",
      "0.2973780227713795\n",
      "0.2972095727973777\n",
      "0.2970413398062977\n",
      "0.2968733234174207\n",
      "0.2967055232508106\n",
      "0.2965379389273125\n",
      "0.29637057006855094\n",
      "0.29620341629692815\n",
      "0.29603647723562254\n",
      "0.29586975250858705\n",
      "0.2957032417405475\n",
      "0.295536944557001\n",
      "0.29537086058421413\n",
      "0.29520498944922136\n",
      "0.29503933077982364\n",
      "0.2948738842045865\n",
      "0.29470864935283864\n",
      "0.29454362585467\n",
      "0.29437881334093047\n",
      "0.2942142114432281\n",
      "0.29404981979392764\n",
      "0.2938856380261486\n",
      "0.2937216657737639\n",
      "0.2935579026713983\n",
      "0.2933943483544267\n",
      "0.29323100245897243\n",
      "0.2930678646219058\n",
      "0.29290493448084265\n",
      "0.29274221167414227\n",
      "0.2925796958409063\n",
      "0.29241738662097705\n",
      "0.29225528365493547\n",
      "0.29209338658410033\n",
      "0.2919316950505259\n",
      "0.291770208697001\n",
      "0.29160892716704695\n",
      "0.2914478501049162\n",
      "0.2912869771555907\n",
      "0.29112630796478045\n",
      "0.29096584217892185\n",
      "0.29080557944517627\n",
      "0.29064551941142813\n",
      "0.29048566172628376\n",
      "0.2903260060390697\n",
      "0.29016655199983116\n",
      "0.2900072992593302\n",
      "0.28984824746904475\n",
      "0.28968939628116663\n",
      "0.2895307453486001\n",
      "0.2893722943249604\n",
      "0.2892140428645723\n",
      "0.28905599062246834\n",
      "0.2888981372543873\n",
      "0.2887404824167731\n",
      "0.28858302576677275\n",
      "0.28842576696223515\n",
      "0.28826870566170953\n",
      "0.2881118415244438\n",
      "0.2879551742103832\n",
      "0.2877987033801688\n",
      "0.2876424286951356\n",
      "0.2874863498173118\n",
      "0.2873304664094168\n",
      "0.28717477813485937\n",
      "0.28701928465773696\n",
      "0.2868639856428337\n",
      "0.2867088807556189\n",
      "0.28655396966224583\n",
      "0.28639925202955013\n",
      "0.28624472752504815\n",
      "0.2860903958169357\n",
      "0.28593625657408644\n",
      "0.2857823094660506\n",
      "0.2856285541630533\n",
      "0.28547499033599316\n",
      "0.285321617656441\n",
      "0.285168435796638\n",
      "0.28501544442949456\n",
      "0.2848626432285889\n",
      "0.28471003186816535\n",
      "0.2845576100231331\n",
      "0.2844053773690646\n",
      "0.28425333358219423\n",
      "0.28410147833941685\n",
      "0.2839498113182864\n",
      "0.28379833219701434\n",
      "0.28364704065446833\n",
      "0.2834959363701707\n",
      "0.28334501902429726\n",
      "0.2831942882976755\n",
      "0.2830437438717836\n",
      "0.2828933854287487\n",
      "0.2827432126513455\n",
      "0.28259322522299496\n",
      "0.2824434228277631\n",
      "0.282293805150359\n",
      "0.28214437187613406\n",
      "0.28199512269108\n",
      "0.2818460572818281\n",
      "0.2816971753356472\n",
      "0.2815484765404427\n",
      "0.28139996058475497\n",
      "0.2812516271577582\n",
      "0.28110347594925855\n",
      "0.2809555066496935\n",
      "0.2808077189501297\n",
      "0.28066011254226203\n",
      "0.2805126871184122\n",
      "0.28036544237152733\n",
      "0.2802183779951786\n",
      "0.28007149368355966\n",
      "0.2799247891314858\n",
      "0.279778264034392\n",
      "0.2796319180883318\n",
      "0.2794857509899763\n",
      "0.2793397624366122\n",
      "0.27919395212614084\n",
      "0.27904831975707667\n",
      "0.2789028650285464\n",
      "0.27875758764028663\n",
      "0.27861248729264354\n",
      "0.2784675636865712\n",
      "0.27832281652363\n",
      "0.27817824550598563\n",
      "0.2780338503364076\n",
      "0.277889630718268\n",
      "0.27774558635554003\n",
      "0.2776017169527969\n",
      "0.2774580222152105\n",
      "0.2773145018485498\n",
      "0.2771711555591798\n",
      "0.2770279830540602\n",
      "0.2768849840407439\n",
      "0.2767421582273762\n",
      "0.27659950532269273\n",
      "0.27645702503601893\n",
      "0.2763147170772681\n",
      "0.27617258115694066\n",
      "0.27603061698612247\n",
      "0.27588882427648365\n",
      "0.27574720274027764\n",
      "0.2756057520903391\n",
      "0.27546447204008373\n",
      "0.2753233623035059\n",
      "0.27518242259517817\n",
      "0.2750416526302497\n",
      "0.274901052124445\n",
      "0.2747606207940626\n",
      "0.27462035835597415\n",
      "0.2744802645276224\n",
      "0.274340339027021\n",
      "0.2742005815727523\n",
      "0.2740609918839666\n",
      "0.2739215696803807\n",
      "0.27378231468227676\n",
      "0.27364322661050117\n",
      "0.273504305186463\n",
      "0.273365550132133\n",
      "0.2732269611700421\n",
      "0.2730885380232807\n",
      "0.27295028041549696\n",
      "0.2728121880708956\n",
      "0.2726742607142369\n",
      "0.2725364980708354\n",
      "0.27239889986655863\n",
      "0.27226146582782584\n",
      "0.272124195681607\n",
      "0.2719870891554213\n",
      "0.27185014597733625\n",
      "0.27171336587596606\n",
      "0.271576748580471\n",
      "0.2714402938205556\n",
      "0.2713040013264679\n",
      "0.27116787082899807\n",
      "0.2710319020594771\n",
      "0.27089609474977594\n",
      "0.270760448632304\n",
      "0.2706249634400079\n",
      "0.27048963890637095\n",
      "0.27035447476541097\n",
      "0.2702194707516798\n",
      "0.270084626600262\n",
      "0.2699499420467736\n",
      "0.2698154168273608\n",
      "0.2696810506786992\n",
      "0.2695468433379921\n",
      "0.2694127945429699\n",
      "0.26927890403188837\n",
      "0.2691451715435279\n",
      "0.2690115968171923\n",
      "0.26887817959270743\n",
      "0.26874491961042024\n",
      "0.26861181661119754\n",
      "0.26847887033642487\n",
      "0.26834608052800546\n",
      "0.26821344692835875\n",
      "0.2680809692804198\n",
      "0.26794864732763757\n",
      "0.2678164808139742\n",
      "0.2676844694839037\n",
      "0.26755261308241085\n",
      "0.26742091135499\n",
      "0.26728936404764436\n",
      "0.267157970906884\n",
      "0.2670267316797257\n",
      "0.2668956461136912\n",
      "0.26676471395680645\n",
      "0.2666339349576\n",
      "0.2665033088651027\n",
      "0.2663728354288459\n",
      "0.2662425143988603\n",
      "0.2661123455256756\n",
      "0.26598232856031845\n",
      "0.2658524632543121\n",
      "0.26572274935967505\n",
      "0.2655931866289196\n",
      "0.2654637748150515\n",
      "0.265334513671568\n",
      "0.26520540295245765\n",
      "0.2650764424121985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2649476318057573\n",
      "0.2648189708885885\n",
      "0.26469045941663316\n",
      "0.2645620971463175\n",
      "0.2644338838345524\n",
      "0.26430581923873203\n",
      "0.2641779031167327\n",
      "0.26405013522691206\n",
      "0.26392251532810773\n",
      "0.26379504317963653\n",
      "0.2636677185412932\n",
      "0.26354054117334946\n",
      "0.26341351083655284\n",
      "0.26328662729212593\n",
      "0.26315989030176495\n",
      "0.26303329962763894\n",
      "0.26290685503238864\n",
      "0.26278055627912533\n",
      "0.2626544031314302\n",
      "0.26252839535335276\n",
      "0.2624025327094103\n",
      "0.2622768149645863\n",
      "0.2621512418843302\n",
      "0.2620258132345555\n",
      "0.26190052878163944\n",
      "0.2617753882924213\n",
      "0.26165039153420233\n",
      "0.2615255382747437\n",
      "0.26140082828226596\n",
      "0.2612762613254481\n",
      "0.2611518371734267\n",
      "0.26102755559579427\n",
      "0.26090341636259873\n",
      "0.26077941924434256\n",
      "0.26065556401198126\n",
      "0.26053185043692273\n",
      "0.2604082782910263\n",
      "0.2602848473466015\n",
      "0.26016155737640717\n",
      "0.2600384081536505\n",
      "0.25991539945198605\n",
      "0.2597925310455147\n",
      "0.25966980270878276\n",
      "0.25954721421678084\n",
      "0.259424765344943\n",
      "0.25930245586914574\n",
      "0.25918028556570694\n",
      "0.259058254211385\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_n_iters):\n",
    "    probs = get_probs(X_train)\n",
    "    print(get_cross_entropy(probs, y_train))\n",
    "    \n",
    "    diff = probs - y_train\n",
    "    \n",
    "    slope_w = np.mean(diff * X_train, axis=0, keepdims=True).T\n",
    "    slope_b = np.mean(diff)\n",
    "    \n",
    "    step_size_weight=learning_rate * slope_w\n",
    "    step_size_bias=learning_rate * slope_b\n",
    "    \n",
    "    weight = weight - step_size_weight\n",
    "    bias = bias - step_size_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the lr model:  95.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the lr model: \", get_accuracy(get_probs(X_test), y_test)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
